# MySql
## 1. 查询语言分类
- DQL（Data Query Language）：数据查询语言，用来查询记录（数据）。
- DML（Data Manipulation Language）：数据操作语言，用来对数据库中表的记录（数据）进行增、删、改操作。
- DDL（Data Definition Language）：数据定义语言，用来定义数据库对象：数据库、表、列等。
- DCL（Data Control Language）：数据控制语言，用来定义数据库的访问权限和安全级别，及创建用户。
- TCL（Transaction Control Language）：事务控制语言，用来对数据库中的事务进行提交、回滚等操作。
## 2. MySql数据类型
### 2.1 数值类型
- 整型：TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT
- 浮点型：FLOAT、DOUBLE
- 位类型：BIT
### 2.2 字符串类型
- CHAR：固定长度字符串
- VARCHAR：可变长度字符串
CHAR 类型的长度就是你定义多少显示多少。占用 M 字节，比如你声明一个 CHAR(20) 的字符串类型，那么每个字符串占用 20 字节，M 的取值范围时 0 - 255。VARCHAR 是可变长的字符串，范围是 0 - 65535，在字符串检索的时候，CHAR 会去掉尾部的空格，而 VARCHAR 会保留这些空格。
- TINYBLOB、TINYTEXT：非常小的文本和二进制数据
- BLOB、TEXT：小的文本和二进制数据
- MEDIUMBLOB、MEDIUMTEXT：中等大小的文本和二进制数据
- LONGBLOB、LONGTEXT：较大的文本和二进制数据
### 2.3 日期和时间类型
- DATE：日期类型
- TIME：时间类型
- YEAR：年份类型
- DATETIME：混合日期和时间类型
### 2.4 枚举和集合类型
- ENUM：枚举类型
- SET：集合类型
## 3. MySql运算符
### 3.1 算术运算符
- 加法运算符：+
- 减法运算符：-
- 乘法运算符：*
- 除法运算符：/
- 求模运算符：%
### 3.2 比较运算符
- 等于运算符：=
- 不等于运算符：!=
- 大于运算符：>
- 大于等于运算符：>=
- 小于运算符：<
- 小于等于运算符：<=
- 判断是否为空运算符：IS NULL
- 判断是否为非空运算符：IS NOT NULL
- 在指定范围内：BETWEEN
- 存在于指定集合：IN
- 通配符匹配：LIKE
- 正则表达式匹配：REGEXP或RLIKE
### 3.3 逻辑运算符
- 逻辑与运算符：AND 或 &&
- 逻辑或运算符：OR 或 ||
- 逻辑非运算符：NOT 或 !
## 3.4 位运算符
- 按位与运算符：&
- 按位或运算符：|
- 按位异或运算符：^
- 左移运算符：<<
- 右移运算符：>>
## 4. MySql函数
- 字符串函数
- 数学函数
- 日期和时间函数
- 加密和压缩函数
- 信息函数
- 格式化函数
- 条件判断函数
- 系统信息函数
- 聚合函数
- 排序函数
## 5. B+ 树
### 5.1 B 树
B树也称B-树,它是一颗多路平衡查找树。定义：
- 每个节点最多有m-1个关键字（可以存有的键值对）。
- 根节点最少可以只有1个关键字。
- 非根节点至少有m/2个关键字。
- 每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。
- 所有叶子节点都位于同一层，或者说根节点到每个叶子节点的长度都相同。
- 每个节点都存有索引和数据，也就是对应的key和value。
### 5.2 B+ 树
B+树其实和B树是非常相似的，我们首先看看**相同点**。
- 根节点至少一个元素
- 非根节点元素范围：m/2 <= k <= m-1

**不同点**。

- B+树有两种类型的节点：内部结点（也称索引结点）和叶子结点。内部节点就是非叶子节点，内部节点不存储数据，只存储索引，数据都存储在叶子节点。
- 内部结点中的key都按照从小到大的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的记录也按照key的大小排列。
- 每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接。
- 父节点存有右孩子的第一个元素的索引。
## 6. 概述
**思维导图**
---
![mysql](/images/16.png)
## 6.1 基础知识
1. 一张数据表一般对应一颗或多颗树的存储，树的数量与建索引的数量有关，每个索引都会有一颗单独的树。
2. 聚簇索引和非聚簇索引：
主键索引也是聚簇索引，非主键索引都是非聚簇索引。**除格式信息外，两种索引的非叶子节点都是只存索引数据的**，比如索引为id，那非叶子节点就是存的id数据。

    叶子节点的区别如下：

    聚簇索引的叶子节点一般情况下存的是这条数据的**所有字段信息**。所以我们`select * from table where id = 1`的时候，都是要去叶子节点拿数据的。

    非聚簇索引的叶子节点存的是这条数据所对应的**主键和索引列信息**。比如这条非聚簇索引是username，然后表的主键是id，那该非聚簇索引的叶子节点存的就是 username 和 id，而不存其他字段。相当于是先从非聚簇索引查到主键的值，再根据主键索引去查数据内容，一般情况下要查两次（除非索引覆盖），这也称之为***回表***，就有点类似于存了个指针，指向了数据存放的真实地址。

3. B+树的查询是从上往下一层层查询的，一般情况下我们认为B+树的高度保持在3层以内是比较好的，也就是上两层是索引，最后一层存数据，这样查表的时候只需要进行3次磁盘IO就可以了(实际上会少一次，因为根节点会常驻内存)，且能够存放的数据量也比较可观。

    如果数据量过大，导致B+数变成4层了，则每次查询就需要进行4次磁盘IO了，从而使性能下降。**所以我们才会去计算InnoDB的3层B+树最多可以存多少条数据。**
4. MySQL每个节点大小默认为16KB，也就是每个节点最多存16KB的数据，可以修改，最大64KB，最小4KB。
5. MySQL查询速度主要取决于磁盘的读写速度，因为MySQL查询的时候每次只读取一个节点到内存中，通过这个节点的数据找到下一个要读取的节点位置，再读取下一个节点的数据，直到查询到需要的数据或者发现数据不存在。
肯定有人要问了，每个节点内的数据难道不用查询吗？这里的耗时怎么不计算？
这是因为读取完整个节点的数据后，会存到内存当中，在内存中查询节点数据的耗时其实是很短的，再配合MySQL的查询方式，时间复杂度差不多为 O(log2N) ，相比磁盘IO来说，可以忽略不计。
## 6.2 MySQL InnoDB 节点的储存内容
在Innodb的B+树中，我们常说的节点被称之为**页(page)**，每个页当中存储了用户数据，所有的页合在一起组成了一颗B+树（当然实际会复杂很多，但我们只是要计算可以存多少条数据，所以姑且可以这么理解😅）。

**页**是InnoDB存储引擎管理数据库的最小磁盘单位，我们常说每个节点16KB，其实就是指每页的大小为16KB。

这16KB的空间，里面需要存储**页格式**信息和**行格式**信息，其中行格式信息当中又包含一些元数据和用户数据。所以我们在计算的时候，要把这些数据的都计算在内。
### 6.2.1 页格式信息
每一页的基本格式，也就是每一页都会包含的一些信息，总结表格如下：
![页格式](/images/17.png)
示意图：
![示意图](/images/18.png)
另外，当新记录插入到 InnoDB 聚集索引中时，InnoDB 会尝试留出 1/16 的页面空闲以供将来插入和更新索引记录。如果按顺序（升序或降序）插入索引记录，则生成的页大约可用 15/16 的空间。如果以随机顺序插入记录，则页大约可用 1/2 到 15/16 的空间。

除了`User Records`和`Free Space`以外所占用的内存是 38+56+26+8=12838 + 56 + 26 + 8 = 12838+56+26+8=128 字节，每一页留给用户数据的空间就还剩 16×15/16×1024−128=1523216（保留了1/16）。

当然，这是最小值，因为我们没有考虑页目录。页目录留在后面根据再去考虑，这个得根据表字段来计算。
### 6.2.2 行格式信息
首先，我觉得有必要提一嘴，MySQL5.6的默认行格式为COMPACT(紧凑)，5.7及以后的默认行格式为DYNAMIC(动态)，不同的行格式存储的方式也是有区别的，还有其他的两种行格式，本文后续的内容主要是基于DYNAMIC(动态)进行讲解的。
每行记录都包含以下这些信息，其中大都是可以从官方文档当中找到的。我这里写的不是特别详细，仅写了一些能够我们计算空间的知识，更详细内容可以去网上搜索 “MySQL 行格式”。
![行格式](/images/19.png)
示意图：
![示意图](/images/20.png)
另外还有几点需要注意：  
- **溢出页（外部页）的存储**

当使用 DYNAMIC 创建表时，InnoDB 会将较长的可变长度列（比如 VARCHAR、VARBINARY、BLOB 和 TEXT 类型）的值剥离出来，存储到一个溢出页上，只在该列上保留一个 20 字节的指针指向溢出页。

列是否存储在页外取决于页大小和行的总大小。当一行太长时，选择最长的列进行页外存储，直到聚集索引记录适合 B+ 树页（文档里没说具体是多少😅）。小于或等于 40 字节的 TEXT 和 BLOB 直接存储在行内，不会分页。

优点：

DYNAMIC 行格式避免了用大量数据填充 B+ 树节点从而导致长列的问题。

DYNAMIC 行格式的想法是，如果长数据值的一部分存储在页外，则通常将整个值存储在页外是最有效的。

使用 DYNAMIC 格式，较短的列会尽可能保留在 B+ 树节点中，从而最大限度地减少给定行所需的溢出页数。

- **字符编码不同情况下的存储**
char 、varchar、text 等需要设置字符编码的类型，在计算所占用空间时，需要考虑不同编码所占用的空间。

varchar、text等类型会有长度字段列表来记录他们所占用的长度，但char是固定长度的类型，情况比较特殊，假设字段 name 的类型为 char(10) ，则有以下情况：
- 对于长度固定的字符编码（比如ASCII码），字段 name 将以固定长度格式存储，ASCII码每个字符占一个字节，那 name 就是占用 10 个字节。
- 对于长度不固定的字符编码（比如utf8mb4），至少将为 name 保留 10 个字节。如果可以，InnoDB会通过修剪尾部空格空间的方式来将其存到 10 个字节中。

    如果空格剪完了还存不下，则将尾随空格修剪为 列值字节长度的最小值（一般是 1 字节）。

    列的最大长度为： 字符编码的最大字符长度×N，比如 name 字段的编码为 utf8mb4，那就是 4×10。
- 大于或等于 768 字节的 char 列会被看成是可变长度字段（就像varchar一样），可以跨页存储。例如，utf8mb4 字符集的最大字节长度为 4，则 char(255) 列将可能会超过 768 个字节，进行跨页存储。
## 6.3 计算
![计算过程](/images/21.jpg)
## 6.4 数据计算总结
根据上面三种不同情况下的计算，可以看出，InnoDB三层B+树情况下的数据存储量范围为**一百二十多万条**到**将近5亿条**，这个跨度还是非常大的，同时我们也计算了一张博客信息表，可以存储**约一千万条**数据。

所以啊，我们在做项目考虑分表的时候还是得多关注一下表的实际情况，而不是盲目的认为两千万数据就是那个临界点。
## 7. MySQL 事务
MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你即需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！
### 7.1 事务基本要素
![事务](/images/22.png)

事务是由一组SQL语句组成的逻辑处理单元，具有4个属性，通常简称为事务的ACID属性。
- A (Atomicity) 原子性：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样
- C (Consistency) 一致性：在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏
- I (Isolation)隔离性：一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰
- D (Durability) 持久性：在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚

**并发事务处理带来的问题**
- 更新丢失（Lost Update)： 事务A和事务B选择同一行，然后基于最初选定的值更新该行时，由于两个事务都不知道彼此的存在，就会发生丢失更新问题
- 脏读(Dirty Reads)：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据
- 不可重复读（Non-Repeatable Reads)：事务 A 多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。
- 幻读（Phantom Reads)：幻读与不可重复读类似。它发生在一个事务A读取了几行数据，接着另一个并发事务B插入了一些数据时。在随后的查询中，事务A就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

    **幻读和不可重复读的区别：**

    - **不可重复读的重点是修改**：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改）

    - **幻读的重点在于新增或者删除**：在同一事务中，同样的条件,，第一次和第二次读出来的记录数不一样。（因为中间有其他事务提交了插入/删除）

**并发事务处理带来的问题的解决办法：**
- 更新丢失”通常是应该完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。

- “脏读” 、 “不可重复读”和“幻读” ，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决：

    - 一种是加锁：在读取数据前，对其加锁，阻止其他事务对数据进行修改。
    - 另一种是数据多版本并发控制（MultiVersion Concurrency Control，简称 **MVCC** 或 MCC），也称为多版本数据库：不用加任何锁， 通过一定机制生成一个数据请求时间点的一致性数据快照 （Snapshot)， 并用这个快照来提供一定级别 （语句级或事务级） 的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本。

**事务隔离级别**

数据库事务的隔离级别有4种，由低到高分别为:
- **READ-UNCOMMITTED(读未提交)**: 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
- **READ-COMMITTED(读已提交)**: 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
- **REPEATABLE-READ(可重复读)**：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
- **SERIALIZABLE(可串行化)**：最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。
# Redis
使用Redis的原因有很多，其中一些主要原因如下：
1. 性能：Redis是基于内存的数据库，读写速度非常快，远超其他基于硬盘存储的数据库。在大并发、高负载的场景下，使用Redis能够显著提升性能，使得系统能够更好地应对请求。
2. 数据结构多样性：Redis支持多种数据结构，如字符串、列表、集合、有序集合和哈希等。这些数据结构可以满足各种不同的业务需求，使得Redis在存储和操作数据时更加灵活和方便。
3. 持久化：虽然Redis主要基于内存存储，但它也支持持久化，可以将数据定期保存到磁盘中，保证数据不会因为意外情况而丢失。同时，持久化也可以用来实现数据的备份和恢复。
4. 高可用性和可扩展性：Redis支持主从复制，可以将数据从一个节点复制到多个从节点。这不仅可以提高系统的可用性，还可以通过分担负载来实现可扩展性。当主节点出现问题时，可以切换到从节点，保证系统的可用性。
### 7.2 MVCC 多版本并发控制
MVCC 的实现是通过保存数据在某个时间点的快照来实现的。也就是说不管需要执行多长时间，每个事物看到的数据都是一致的。

典型的MVCC实现方式，分为**乐观（optimistic）并发控制和悲观（pressimistic）并发控制**。下边通过 InnoDB的简化版行为来说明 MVCC 是如何工作的。

InnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现。这两个列，一个保存了行的创建时间，一个保存行的过期时间（删除时间）。当然存储的并不是真实的时间，而是系统版本号（system version number）。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。

**REPEATABLE READ（可重读）隔离级别下MVCC如何工作：**
- SELECT

    InnoDB会根据以下两个条件检查每行记录：
    - InnoDB只查找版本早于当前事务版本的数据行，这样可以确保事务读取的行，要么是在开始事务之前已经存在要么是事务自身插入或者修改过的
    - 行的删除版本号要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行在事务开始之前未被删除
    
    只有符合上述两个条件的才会被查询出来
- INSERT：InnoDB为新插入的每一行保存当前系统版本号作为行版本号
- DELETE：InnoDB为删除的每一行保存当前系统版本号作为行删除标识
- UPDATE：InnoDB为插入的一行新纪录保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为删除标识

保存这两个额外系统版本号，使大多数操作都不用加锁。使数据操作简单，性能很好，并且也能保证只会读取到符合要求的行。不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作和一些额外的维护工作。

MVCC 只在 COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作。

### 7.3 事务日志
InnoDB 使用日志来减少提交事务时的开销。因为日志中已经记录了事务，就无须在每个事务提交时把缓冲池的脏块刷新(flush)到磁盘中。

事务修改的数据和索引通常会映射到表空间的随机位置，所以刷新这些变更到磁盘需要很多随机 IO。

InnoDB 假设使用常规磁盘，随机IO比顺序IO昂贵得多，因为一个IO请求需要时间把磁头移到正确的位置，然后等待磁盘上读出需要的部分，再转到开始位置。

InnoDB 用日志把随机IO变成顺序IO。一旦日志安全写到磁盘，事务就持久化了，即使断电了，InnoDB可以重放日志并且恢复已经提交的事务。

InnoDB 使用一个后台线程智能地刷新这些变更到数据文件。这个线程可以批量组合写入，使得数据写入更顺序，以提高效率。

事务日志可以帮助提高事务效率：
- 使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。
- 事务日志采用的是追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说要快得多。
- 事务日志持久以后，内存中被修改的数据在后台可以慢慢刷回到磁盘。
- 如果数据的修改已经记录到事务日志并持久化，但数据本身没有写回到磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这一部分修改的数据。

目前来说，大多数存储引擎都是这样实现的，我们通常称之为**预写式日志（Write-Ahead Logging）**，修改数据需要写两次磁盘。

### 7.4 事务的实现
事务的实现是基于数据库的存储引擎。不同的存储引擎对事务的支持程度不一样。MySQL 中支持事务的存储引擎有 InnoDB 和 NDB。

事务的实现就是如何实现ACID特性。

**事务的隔离性是通过锁实现，而事务的原子性、一致性和持久性则是通过事务日志实现 。**

事务日志包括：**重做日志redo**和**回滚日志undo**
- redo log（重做日志） 实现持久化和原子性

    在innoDB的存储引擎中，事务日志通过重做(redo)日志和innoDB存储引擎的日志缓冲(InnoDB Log Buffer)实现。事务开启时，事务中的操作，都会先写入存储引擎的日志缓冲中，在事务提交之前，这些缓冲的日志都需要提前刷新到磁盘上持久化，这就是DBA们口中常说的“日志先行”(Write-Ahead Logging)。当事务提交之后，在Buffer Pool中映射的数据文件才会慢慢刷新到磁盘。此时如果数据库崩溃或者宕机，那么当系统重启进行恢复时，就可以根据redo log中记录的日志，把数据库恢复到崩溃前的一个状态。未完成的事务，可以继续提交，也可以选择回滚，这基于恢复的策略而定。

    在系统启动的时候，就已经为redo log分配了一块连续的存储空间，以顺序追加的方式记录Redo Log，通过顺序IO来改善性能。所有的事务共享redo log的存储空间，它们的Redo Log按语句的执行顺序，依次交替的记录在一起。
- undo log（回滚日志）  实现一致性

    undo log 主要为事务的回滚服务。在事务执行的过程中，除了记录redo log，还会记录一定量的undo log。undo log记录了数据在每个操作前的状态，如果事务执行过程中需要回滚，就可以根据undo log进行回滚操作。单个事务的回滚，只会回滚当前事务做的操作，并不会影响到其他的事务做的操作。

    Undo记录的是已部分完成并且写入硬盘的未完成的事务，默认情况下回滚日志是记录下表空间中的（共享表空间或者独享表空间）


二种日志均可以视为一种恢复操作，redo_log是恢复提交事务修改的页操作，而undo_log是回滚行记录到特定版本。二者记录的内容也不同，redo_log是物理日志，记录页的物理修改操作，而undo_log是逻辑日志，根据每行记录进行记录。

又引出个问题：你知道MySQL 有多少种日志吗？
- 错误日志：记录出错信息，也记录一些警告信息或者正确的信息。
- 查询日志：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行。
- 慢查询日志：设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。
- 二进制日志：记录对数据库执行更改的所有操作。
- 中继日志：中继日志也是二进制日志，用来给slave 库恢复
- 事务日志：重做日志redo和回滚日志undo
## 8. MySQL调优
MySQL调优是一项关键任务，可以提高数据库性能和响应时间。以下是一些建议，但请注意，具体的调优方法可能因数据库版本、硬件配置和应用程序需求而异。

1. **优化查询语句**：
   - 确保使用索引来加速查询。
   - 避免使用SELECT *，只选择需要的列。
   - 使用合适的数据类型，避免使用过大的数据类型，以减小存储和检索的开销。

2. **索引优化**：
   - 确保表的关键列有索引。
   - 调查慢查询日志，了解哪些查询需要更好的索引。
   - 注意索引的选择，避免过多或过少的索引。

3. **配置缓存**：
   - 考虑适当配置MySQL的缓存，如查询缓存、表缓存等。
   - 使用InnoDB存储引擎，因为它提供了更好的缓存管理。

4. **调整连接池**：
   - 优化连接池设置，确保不会占用过多系统资源。
   - 调整`max_connections`参数，以防止连接过多。

5. **硬件和服务器参数调整**：
   - 根据服务器的物理内存和CPU核心数调整`innodb_buffer_pool_size`和`innodb_log_file_size`等参数。
   - 考虑使用专用的数据库服务器，以确保数据库有足够的资源。

6. **监控和日志**：
   - 启用MySQL的慢查询日志，并定期分析它以找出潜在的性能问题。
   - 使用监控工具，如Prometheus、Percona Monitoring and Management（PMM）等，以实时监控数据库性能。

7. **分区和分表**：
   - 对于大型表，考虑使用分区来提高查询性能。
   - 对于超大型表，可以考虑分表策略。

8. **升级MySQL版本**：
   - 如果可能的话，考虑升级到最新的MySQL版本，以获得性能改进和bug修复。

9. **使用连接池**：
   - 使用连接池来管理数据库连接，以减轻数据库服务器的压力。

10. **优化存储引擎参数**：
    - 针对使用的存储引擎（通常是InnoDB），调整相关参数以优化性能。

在进行任何调整之前，请确保对数据库的备份，以防止意外的数据丢失。最好在生产环境之外进行测试，并且逐个参数进行调整，以了解每个变更的影响。
## 9. 范式
三个范式在数据库设计中非常重要，它们的主要作用是减少数据冗余，建立结构合理的数据库，从而提高数据存储和使用的性能。

具体来说，第一范式（1NF）确保每列的原子性，即每列都是不可再分的最小数据单元。这有助于消除数据冗余和保证数据的完整性。第二范式（2NF）在第一范式的基础上更进一步，要求表中的每列都和主键相关，而不是间接相关。这样可以进一步减少数据冗余和提高数据的一致性。第三范式（3NF）在第二范式的基础上更进一步，要求每列都和主键直接相关，而不是间接相关。这样可以消除数据冗余和保证数据的完整性。

通过遵循这三个范式，可以建立一个结构合理、性能优越的数据库，从而提高数据的存储和使用效率。同时，也有助于减少数据不一致、冗余和错误等问题。因此，在进行数据库设计时，应该充分考虑并遵循这三个范式。
- 第一范式（1NF）：数据库表中的字段都是单一属性的，不可再分。这个单一属性由基本类型构成，包括整型、实数、字符型、逻辑型、日期型等。
- 第二范式（2NF）：数据库表中不存在非关键字段对任一候选关键字段的部分函数依赖（部分函数依赖指的是存在组合关键字中的某些字段决定非关键字段的情况），也即所有非关键字段都完全依赖于任意一组候选关键字。
- 第三范式（3NF）：在第二范式的基础上，数据表中如果不存在非关键字段对任一候选关键字段的传递函数依赖则符合第三范式。所谓传递函数依赖，指的是如 果存在"A → B → C"的决定关系，则C传递函数依赖于A。因此，满足第三范式的数据库表应该不存在如下依赖关系： 关键字段 → 非关键字段 x → 非关键字段y。